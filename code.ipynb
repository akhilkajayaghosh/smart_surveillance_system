{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akhil\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\akhil\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akhil\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akhil\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akhil\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microphone is ON. Listening for anomalies...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "[2025-01-11 18:02:24.804739] Detected: Explosions (Confidence: 0.92)\n",
      "Anomalous audio saved: anomalous_audio/Explosions_20250111_180224.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "[2025-01-11 18:02:29.784268] Detected: Explosions (Confidence: 0.90)\n",
      "Anomalous audio saved: anomalous_audio/Explosions_20250111_180229.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "[2025-01-11 18:02:34.764060] Detected: Explosions (Confidence: 0.89)\n",
      "Anomalous audio saved: anomalous_audio/Explosions_20250111_180234.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "[2025-01-11 18:02:39.749625] Detected: Explosions (Confidence: 0.86)\n",
      "Anomalous audio saved: anomalous_audio/Explosions_20250111_180239.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "[2025-01-11 18:02:44.806877] Detected: Explosions (Confidence: 0.94)\n",
      "Anomalous audio saved: anomalous_audio/Explosions_20250111_180244.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "[2025-01-11 18:02:49.742235] Detected: Explosions (Confidence: 0.90)\n",
      "Anomalous audio saved: anomalous_audio/Explosions_20250111_180249.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "[2025-01-11 18:02:54.727670] Detected: Explosions (Confidence: 0.95)\n",
      "Anomalous audio saved: anomalous_audio/Explosions_20250111_180254.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "[2025-01-11 18:02:59.728408] Detected: Explosions (Confidence: 0.86)\n",
      "Anomalous audio saved: anomalous_audio/Explosions_20250111_180259.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "[2025-01-11 18:03:04.718565] Detected: Explosions (Confidence: 0.89)\n",
      "Anomalous audio saved: anomalous_audio/Explosions_20250111_180304.wav\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "[2025-01-11 18:03:09.705898] Detected: Explosions (Confidence: 0.93)\n",
      "Anomalous audio saved: anomalous_audio/Explosions_20250111_180309.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pyaudio\n",
    "import wave\n",
    "import threading\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "\n",
    "# === Model Loading ===\n",
    "yolo_model_path = 'yolo_v1 (2).pt'  # YOLO model path\n",
    "\n",
    "# Load models\n",
    "audio_model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "yamnet_model = hub.load('https://www.kaggle.com/models/google/yamnet/TensorFlow2/yamnet/1')\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "\n",
    "# Ensure required directories exist\n",
    "os.makedirs(\"anomalous_videos\", exist_ok=True)\n",
    "os.makedirs(\"anomalous_audio\", exist_ok=True)\n",
    "\n",
    "# Index-to-label mapping for YAMNet\n",
    "index_to_label = {\n",
    "    0: \"Emergency_alert_sound\",\n",
    "    1: \"Explosions\",\n",
    "    2: \"Gunshots\",\n",
    "    3: \"Human screams\",\n",
    "    4: \"Bottles breaking\",\n",
    "    5: \"Dog bark\"\n",
    "}\n",
    "\n",
    "# === Audio Threat Detection ===\n",
    "\n",
    "# Audio recording configuration\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "RECORD_SECONDS = 5  # Analyze 5-second chunks\n",
    "AUDIO_FOLDER = \"anomalous_audio\"\n",
    "\n",
    "def preprocess_audio(audio_waveform, target_length=16000 * 5):\n",
    "    \"\"\"Pad or truncate audio waveform to 5 seconds (16kHz).\"\"\"\n",
    "    if len(audio_waveform) < target_length:\n",
    "        audio_waveform = np.pad(audio_waveform, (0, target_length - len(audio_waveform)))\n",
    "    else:\n",
    "        audio_waveform = audio_waveform[:target_length]\n",
    "    audio_waveform = audio_waveform.astype(np.float32) / np.max(np.abs(audio_waveform))\n",
    "    return audio_waveform\n",
    "\n",
    "def predict_audio_stream(audio_chunk, confidence_threshold=0.5):\n",
    "    \"\"\"Predict the class of a given audio chunk.\"\"\"\n",
    "    processed_audio = preprocess_audio(audio_chunk)\n",
    "    _, yamnet_embeddings, _ = yamnet_model(processed_audio)\n",
    "    avg_embedding = tf.reduce_mean(yamnet_embeddings, axis=0).numpy().reshape(1, -1)\n",
    "    prediction = audio_model.predict(avg_embedding)\n",
    "    predicted_class_index = np.argmax(prediction, axis=1)[0]\n",
    "    confidence = prediction[0][predicted_class_index]\n",
    "    if confidence >= confidence_threshold:\n",
    "        return index_to_label[predicted_class_index], confidence\n",
    "    return \"Unknown\", confidence\n",
    "\n",
    "def record_and_analyze_audio():\n",
    "    \"\"\"Continuously record audio from the microphone and analyze it.\"\"\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE,\n",
    "                        input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"Microphone is ON. Listening for anomalies...\")\n",
    "    while True:\n",
    "        try:\n",
    "            frames = []\n",
    "            for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "                data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "                frames.append(np.frombuffer(data, dtype=np.int16))\n",
    "\n",
    "            # Convert frames to a single audio array\n",
    "            audio_data = np.concatenate(frames, axis=0).astype(np.float32)\n",
    "            predicted_class, confidence = predict_audio_stream(audio_data)\n",
    "\n",
    "            if predicted_class != \"Unknown\":\n",
    "                print(f\"[{datetime.now()}] Detected: {predicted_class} (Confidence: {confidence:.2f})\")\n",
    "\n",
    "                # Save the anomalous audio to a file\n",
    "                filename = f\"{AUDIO_FOLDER}/{predicted_class}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.wav\"\n",
    "                with wave.open(filename, 'wb') as wf:\n",
    "                    wf.setnchannels(CHANNELS)\n",
    "                    wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "                    wf.setframerate(RATE)\n",
    "                    wf.writeframes(b''.join(frames))\n",
    "                print(f\"Anomalous audio saved: {filename}\")\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Microphone stream stopped.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "# === Video Threat Detection ===\n",
    "def process_video_stream(video_source=0):\n",
    "    cap = cv2.VideoCapture(video_source)  # Use 0 for webcam\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video stream\")\n",
    "        return\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "\n",
    "    out = None\n",
    "    recording = False\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Warning: Failed to capture frame, skipping...\")\n",
    "            continue\n",
    "\n",
    "        results = yolo_model.predict(frame, conf=0.5, verbose=False)\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        anomalies_detected = False\n",
    "        if results[0].boxes:\n",
    "            for box in results[0].boxes:\n",
    "                cls_id = int(box.cls)\n",
    "                confidence = box.conf.item()\n",
    "                label = yolo_model.names[cls_id]\n",
    "\n",
    "                print(f\"[{datetime.now()}] Detected: {label} (Confidence: {confidence:.2f})\")\n",
    "                if label in [\"violence\", \"weaponized\"]:\n",
    "                    anomalies_detected = True\n",
    "\n",
    "                    if not recording:\n",
    "                        video_filename = f\"anomalous_videos/{label}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4\"\n",
    "                        out = cv2.VideoWriter(video_filename, fourcc, fps, (frame_width, frame_height))\n",
    "                        recording = True\n",
    "                        print(f\"[{datetime.now()}] Recording started: {video_filename}\")\n",
    "\n",
    "                    if out:\n",
    "                        out.write(frame)\n",
    "                    break\n",
    "\n",
    "        if not anomalies_detected and recording:\n",
    "            print(f\"[{datetime.now()}] Anomaly ended. Stopping recording.\")\n",
    "            recording = False\n",
    "            if out:\n",
    "                out.release()\n",
    "                out = None\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Exit requested. Stopping program.\")\n",
    "            break\n",
    "\n",
    "    if recording and out:\n",
    "        out.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# === Unified System ===\n",
    "def unified_system(video_source=0):\n",
    "    \"\"\"Unified system for real-time audio and video threat detection.\"\"\"\n",
    "    # video_thread = threading.Thread(target=process_video_stream, args=(video_source,))\n",
    "    audio_thread = threading.Thread(target=record_and_analyze_audio)\n",
    "\n",
    "    # video_thread.start()\n",
    "    audio_thread.start()\n",
    "\n",
    "    # video_thread.join()\n",
    "    audio_thread.join()\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    unified_system(video_source=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
