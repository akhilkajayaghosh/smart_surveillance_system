{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step \n",
      "Predicted class : Explosions\n",
      "The audio file does not belong to any trained class.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import threading\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "\n",
    "# === Model Loading ===\n",
    "yolo_model_path = 'yolo_v1 (2).pt'  # YOLO model path\n",
    "\n",
    "# Load models\n",
    "audio_model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "\n",
    "# Ensure required directories exist\n",
    "os.makedirs(\"anomalous_videos\", exist_ok=True)\n",
    "os.makedirs(\"anomalous_audio\", exist_ok=True)\n",
    "\n",
    "# Index-to-label mapping for YAMNet\n",
    "index_to_label = {\n",
    "    0: \"Emergency_alert_sound\",\n",
    "    1: \"Explosions\",\n",
    "    2:\"Gunshots\",\n",
    "    3:\"Human screams\",\n",
    "    4:\"bottles breaking\",\n",
    "    5:\"dog bark\"\n",
    "    # Add more labels as per your trained model\n",
    "}\n",
    "\n",
    "def load_audio(file_path, target_sr=16000):\n",
    "    \"\"\"Load audio and preprocess to 16 kHz mono.\"\"\"\n",
    "    audio, sr = librosa.load(file_path, sr=target_sr, mono=True)\n",
    "    return audio\n",
    "\n",
    "def preprocess_audio(audio_waveform, target_length=16000 * 5):\n",
    "    \"\"\"Pad or truncate the waveform to 5 seconds (80,000 samples) and reshape into chunks.\"\"\"\n",
    "    if len(audio_waveform) < target_length:\n",
    "        audio_waveform = np.pad(audio_waveform, (0, target_length - len(audio_waveform)))\n",
    "    else:\n",
    "        audio_waveform = audio_waveform[:target_length]\n",
    "\n",
    "    # Normalize between -1 and 1\n",
    "    audio_waveform = audio_waveform.astype(np.float32)\n",
    "    audio_waveform /= np.max(np.abs(audio_waveform))\n",
    "\n",
    "    # Reshape into chunks of 1024\n",
    "    num_chunks = target_length // 1024  # Ensure the total length is divisible by 1024\n",
    "    reshaped_audio = audio_waveform[:num_chunks * 1024].reshape(-1, 1024)\n",
    "    return reshaped_audio\n",
    "\n",
    "\n",
    "def extract_audio_features(audio_waveform):\n",
    "    # \"\"\"Use YAMNet to extract audio features.\"\"\"\n",
    "    # model_url = \"https://tfhub.dev/google/yamnet/1\"\n",
    "    # yamnet_model = hub.load(model_url)\n",
    "\n",
    "    # YAMNet model expects a 1D audio waveform, not a 2D input.\n",
    "    scores, embeddings, spectrogram = audio_model(audio_waveform)\n",
    "    \n",
    "    # Extract the mean of embeddings (1024 features)\n",
    "    return np.mean(embeddings, axis=0).reshape(1, -1)  # Shape (1, 1024)\n",
    "\n",
    "def predict_audio(audio_file, confidence_threshold=0.7):\n",
    "    audio = load_audio(audio_file)\n",
    "    processed_audio = preprocess_audio(audio)  # Returns shape (batch_size, 1024)\n",
    "\n",
    "    # Feed batches into the model\n",
    "    predictions = audio_model.predict(processed_audio)  # Returns predictions for each chunk\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)\n",
    "    confidence = np.max(predictions, axis=1)\n",
    "\n",
    "    # Aggregate results if necessary\n",
    "    overall_class = index_to_label[np.argmax(np.bincount(predicted_class_index))]\n",
    "    print(\"Predicted class :\", overall_class)\n",
    "    overall_confidence = np.mean(confidence)\n",
    "\n",
    "    if overall_confidence < confidence_threshold:\n",
    "        return \"Unknown\", overall_confidence\n",
    "\n",
    "    return overall_class, overall_confidence\n",
    "\n",
    "\n",
    "# === Video Threat Detection ===\n",
    "def process_video_stream(video_source=0):\n",
    "    cap = cv2.VideoCapture(video_source)  # Use 0 for webcam\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video stream\")\n",
    "        return\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n",
    "\n",
    "    out = None\n",
    "    recording = False\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Warning: Failed to capture frame, skipping...\")\n",
    "            continue\n",
    "\n",
    "        results = yolo_model.predict(frame, conf=0.5, verbose=False)\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        anomalies_detected = False\n",
    "        if results[0].boxes:\n",
    "            for box in results[0].boxes:\n",
    "                cls_id = int(box.cls)\n",
    "                confidence = box.conf.item()\n",
    "                label = yolo_model.names[cls_id]\n",
    "\n",
    "                print(f\"[{datetime.now()}] Detected: {label} (Confidence: {confidence:.2f})\")\n",
    "                if label in [\"violence\", \"weaponized\"]:\n",
    "                    anomalies_detected = True\n",
    "\n",
    "                    if not recording:\n",
    "                        video_filename = f\"anomalous_videos/{label}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4\"\n",
    "                        out = cv2.VideoWriter(video_filename, fourcc, fps, (frame_width, frame_height))\n",
    "                        recording = True\n",
    "                        print(f\"[{datetime.now()}] Recording started: {video_filename}\")\n",
    "\n",
    "                    if out:\n",
    "                        out.write(frame)\n",
    "                    break\n",
    "\n",
    "        if not anomalies_detected and recording:\n",
    "            print(f\"[{datetime.now()}] Anomaly ended. Stopping recording.\")\n",
    "            recording = False\n",
    "            if out:\n",
    "                out.release()\n",
    "                out = None\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(\"Exit requested. Stopping program.\")\n",
    "            break\n",
    "\n",
    "    if recording and out:\n",
    "        out.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# === Unified System ===\n",
    "def unified_system(audio_file=None, video_source=0):\n",
    "    \"\"\"Unified system for audio and video threat detection.\"\"\"\n",
    "    video_thread = threading.Thread(target=process_video_stream, args=(video_source,))\n",
    "    audio_thread = None\n",
    "\n",
    "    if audio_file:\n",
    "        def audio_task():\n",
    "            predicted_class, confidence = predict_audio(audio_file, confidence_threshold=0.7)\n",
    "            # print(predicted_class, confidence)\n",
    "            if predicted_class == \"Unknown\":\n",
    "                print(\"The audio file does not belong to any trained class.\")\n",
    "            else:\n",
    "                print(f\"Predicted class: {predicted_class}\")\n",
    "                print(f\"Confidence: {confidence:.2f}\")\n",
    "\n",
    "        audio_thread = threading.Thread(target=audio_task)\n",
    "    # video_thread.start()\n",
    "    if audio_thread:\n",
    "        audio_thread.start()\n",
    "    # video_thread.start()\n",
    "    if audio_thread:\n",
    "        audio_thread.join()\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    audio_file_path = \"R01-53-Medium-Sized Dog Barking.wav.mp3\"  # Replace with your audio file path\n",
    "    unified_system(audio_file=audio_file_path, video_source=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
